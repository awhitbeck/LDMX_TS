This file includes all the important files for training the BDT from the nfs server
and then calculating BDT values locally. Here is a brief list of each file, containing what they do. After listing what they do a skeleton diagram will
be included in each description with input and output files. At the end I will also include a sequence for how they are all run.

This will be the barebones of what was needed to create the BDT,
so previous versions of each of the files are available if needed (likely not). Just ask me if you want them.

BDTMakeAndCutNoRead.C

This file takes oneandthreesig.root or oneandthreeback.root files from the nfs server. These are files drawn from the nfs server with separation into good and bad tracks based on
beamEfrac (a truth variable). With these files it trains the BDT and includes the training information in a root file called "TMVA{something}.root". 
This file will contain all relevant BDT responce curves and the like. Importantly in the directory it was run it will create a file called "dataset" 
which contains the BDT weighting information used for BDTMakeAndCutNoRead.C

input: oneandthreesig.root and oneandthreeback.root from the nfs server with the n electron events with signal and background structure
output: TMVA{something}.root, a directory named /dataset/ with the training info

BDTMakeAndCut2.C

This file takes the weighting information generated in "dataset" from BDTMakeAndCut.C and runs them on OneAll,TwoAll,ThreeAll.root files from the nfs server. 
These are files drawn from the nfs server with no separation into good and bad tracks, but just flattened to only include those thing required by the BDT. 
It will generate the same files w/ same information but now to each track it will associate a BDT value. For my results I generated confusion matrices by looking
at select.numTra from these files before and after a BDT cut. Furthermore another cool metric is plotting select.numTra:select.BDTval, which generates for TwoVal a 
moving column of the confusion matrix with BDT and is easy visual info that the BDT is identifying the appropriatte features. Btw you can probably jerry rig other files 
to create confusion matrices from LDMX_TS, but I just read the information off of the Histograms I mentioned

input: The directory /dataset/ and OneAll, TwoAll.root, etc. unstructured nElectron events from nfs server
output: select.root, just OneAll but now each event has a BDT score

BDTValueDiscern.C

The TMVA files generated by BDTMakeAndCut2.C have an ROC curve which tells you what efficiencies you can expect for certain removal of bad tracks. It doesn't, however, 
tell you what BDT values you need to achieve these values. This .C file can be used to explore BDT values and actually find the points on the ROC from TMVA files in 
BDTMakeAndCut2.C

input:oneandthreesig.root,oneandthreeback.root
output:N/A

namelist,namelist1and3.txt,namelist2, etc.

All of these namelist txt files simply contain the list of names of the nfs servers' one million events. These names are used by the readN.C, readPurpose.C files (etc) 
to recursively go through each of the 100 100,000 event files and generate from them either training data for the BDT or files to test the BDT on

input:N/A
output:N/A

readPurpose4.C

This file takes nfs sample data whose names are fed into it from the namelist and creates large signal and brackground files from them. Its not too complicated what it
does with them: it just from the TTrees of the nfs data draws residual, numTra, uCl,dCl, etc and adds them to a bare bones root file. What entries it decides to put in
signal and background you should be able to see by the big and immediattely sequential if statments for the signal and background. The background (good tracks) only accepts
events which have beamEfrac 1 (which the file also finds), and you can set the acceptance value of the bad tracks (currently set to less than beamEfrac of .5). This will
normally need to be run ON THE NFS SERVER, NOT LOCALLY.

input:namelist.txt, namelist1.txt, etc.
output: oneandthreesig.root, oneandthreeback.root, etc.

readPurpose2.C

This file takes nfs sample data whose names are fed into it same as readPurpose4.C. The only thing thats different is that it does not separate the data to train it: it
produces the files we test the BDT upon. In this manner readPurpose4 normally only uses namelist1and3.txt, while this can use any of them. It will generate a root file called 
"allOfThem.root" on the NFS server. MUST BE RUN ON THE NFS SERVER, NOT LOCALLY. Once you have "allOfThem.root", you can use BDTMakeAndCut2.C to test your BDT on allOfThem to 
get select.root (which is mentions in BDTMakeAndCut2) and all the the various performance metrics like confusion matrices. You will need to have generated TMVA data from 
readPurpose4.C and BDTMakeAndCutNoRead beforehand however.

input:namelist.txt, namelist1.txt, etc.
output: OneAll.root, TwoAll.root, etc.

2DCutEllipse.C

This file performs a 2D cut on residual AND Timing information. The relevant diagram was included in one of the presentations. It did not perform much better than just the 
one dimensional selection, and really it doesn't serve much of a purpose. It is just included in case a person finds the diagram of this selection and wants the code for it.

input:oneandthreesig.root, oneandthreeback.root
output:N/A

ROCcurves.C

This performs the simple 1 d cut included in the "overview presentation" and calculates the ROC curves. The arrays supplied in x[j],y[j] were just plotted using python 
in scratch grapher.py by putting the data into text files "scratch1-4.txt". These are included so the file will actually run

input:oneandthreesig.root, oneandthreeback.root
output:scratch1-4.txt

scratch1-4.txt

Look directly at the previous inclusion.

input:N/A
output:N/A

scratchgrapher.py

Images the data from ROCcurves.C

input:scratch1-4.txt
output:N/A

Run sequences:

This first most complicated sequence will take you through all the steps to generate select.root, the ultimate output of the BDT upon which its performance in track reduction
can be directly evaluated.

################################################################################################################################################

GENERATING SELECT.ROOT TO GET CONFUSION MATRIX VALUES FROM BDT CUTS

Step 1: Download readPurpose2.C,readPurpose4.C,namelist2.txt, and namelist1and3.txt onto /nfs/slac/g/ldmx/users/{yourname}. Can be done by git cloning this LDMX_TS branch

Step 2: run readPurpose4.C as is (should be configured to use namelist1and3.txt):

cd /nfs/slac/g/ldmx/users/{yourname}
root
*root browser opens*
.x readPurpose4.C

Step 3: run readPurpose2.C after changing "ifstream f("namelist.txt")" to "ifstream f("namelist2.txt")" and string line2 to have
"v2.3.0-2e" at the end to configure for the two electron files

root
*root browser opens*
.x readPurpose2.C

You should now have in /nfs/slac/g/ldmx/users/{yourname} the files "allOfThem.root" (which you should rename TwoAll.root) and "signal.root", "background.root"

Step 3: scp these files from the nfs server to your local computer (I do this because I cant run GUI on the nfs,
maybe you can do all this yourself from the remote server)

Step 4: Run BDTMakeAndCutNoRead to train the BDT. You will need to change myFile and myFile2 instantiation to the appropriatte names of the signal and background fiels (respectively)
that you names when you copied them from the nfs server.

root
*root browser opens*
.x BDTMakeAndCutNoRead

Step 5: Run BDTMakeAndCut2.C. You only need to change the myFile3 to "TwoAll.root" or whatever you called this file when you copied it from the remote server.

root
*root browser opens*
.x BDTMakeAndCut2.C.

Step 6: Open the resulting select.root file on TBrowser. The effect of BDT selection on numTra can be seen by making the histogram "select->Draw("select.numTra>>h(100,0,6)","select.BDTscore>{yourvalue}","colz")"
To see how the number of tracks observed changes, change "{yourval}"

##########################################################################################################################################

RUNNING VARIOUS ANALYSIS Cutting/Visualization CODE

  Running ROCcurves.C:
  Step 1: Change the myFile instantiation in ROCcurves.C from slacback4.root to oneandthreeback.root and slacsig4.root to the equivalent oneandthre...
  Now run it as usual
  
  root
  *root browser opens*
  .x ROCcurves.C
  
  Step 2: Copy down the output of ROCcurves into a textfile called "scratchoneandthree.txt"
  
  Step 3: Change "scratchgrapher.py" to where it only reads in one file into one array ax,ay (just involves delection of other arrays)
  the name of that file should be "scratchoneandthree.txt"
  
  These instructions should generate the ROC curve for oneandthree electron events. You can alternatively do the last process for a different namelist (i.e. train only on two electron
  events for instance). The original python file included ran the BDT trainer independently on each of the n electron events by thems selves, and it currently configured to draw ROC
  curves for all of them to compare, but that was a a couple steps ahead of what I thought was appropriatte to include in depth here.
  
  Running 2DCutEllipse
  
  Do the first step of the last sequence exchanging .x ROCcurves.C to .x 2DEllipse.C. This will give you a single number because the cut was a single cut corresponding to a complicated picture
  included in a presentation I gave. Please email me if you want more info, but I don't think this particular graph is too important.
  
  Running BDTValueDiscern.C
  
  Step1: Open the fule and change cutval to the BDT value you want to set (and find where it corresponds to on the ROC curve). This is a rinky dinky way to do it, but it works if you are patient enough
  to try enough values. You will also need to change myFile3 and myFile3 names to the appropriate signal and backgroudn files
  
  Step2: Run it
  
  root
  *root browser opens*
  .x BDTValueDiscern.C
  
  You will get an output corresponding to the BadRate (i.e. number of bad events over good events) and "LeftOverGood" (number of good events not selected out by the cut).
  
